question,incorrect_0,incorrect_1,incorrect_2,incorrect_3,correct_0,correct_1,correct_2
"Mountkirk Games has deployed their new backend on Google Cloud Platform (GCP). You want to create a through testing process for new versions of the backend before they are released to the public. You want the testing environment to scale in an economical way. How should you design the process?
",Use the existing infrastructure to test the GCP-based backend at scale,Build stress tests into each component of your application using resources internal to GCP to simulate load,"Create a set of static environments in GCP to test different levels of load ג€"" for example, high, medium, and low",,Create a scalable environment in GCP for simulating production load,,
"Auditors visit your teams every 12 months and ask to review all the Google Cloud Identity and Access Management (Cloud IAM) policy changes in the previous 12 months. You want to streamline and expedite the analysis and audit process.
What should you do?
",Create custom Google Stackdriver alerts and send them to the auditor,Use cloud functions to transfer log entries to Google Cloud SQL and use ACLs and views to limit an auditor's view,Enable Google Cloud Storage (GCS) log export to audit logs into a GCS bucket and delegate access to the bucket,,Enable Logging export to Google BigQuery and use ACLs and views to scope the data shared with the auditor,,
"TerramEarth has equipped all connected trucks with servers and sensors to collect telemetry data. Next year they want to use the data to train machine learning models. They want to store this data in the cloud while reducing costs.
What should they do?
","Have the vehicle's computer compress the data in hourly snapshots, and store it in a Google Cloud Storage (GCS) Nearline bucket","Push the telemetry data in real-time to a streaming dataflow job that compresses the data, and store it in Google BigQuery","Push the telemetry data in real-time to a streaming dataflow job that compresses the data, and store it in Cloud Bigtable",,"Have the vehicle's computer compress the data in hourly snapshots, and store it in a GCS Coldline bucket",,
"Your customer wants to capture multiple GBs of aggregate real-time key performance indicators (KPIs) from their game servers running on Google Cloud Platform and monitor the KPIs with low latency. How should they capture the KPIs?
","Store time-series data from the game servers in Google Bigtable, and view it using Google Data Studio.","Schedule BigQuery load jobs to ingest analytics files uploaded to Cloud Storage every ten minutes, and visualize the results in Google Data Studio.","Insert the KPIs into Cloud Datastore entities, and run ad hoc analysis and visualizations of them in Cloud Datalab.",,"Output custom metrics to Stackdriver from the game servers, and create a Dashboard in Stackdriver Monitoring Console to view them.",,
"Your company places a high value on being responsive and meeting customer needs quickly. Their primary business objectives are release speed and agility. You want to reduce the chance of security errors being accidentally introduced.
Which two actions can you take? (Choose two.)
",Ensure every code check-in is peer reviewed by a security SME,Ensure you have stubs to unit test all interfaces between components,Enable code signing and a trusted binary repository integrated with your CI/CD pipeline,,Use source code security analyzers as part of the CI/CD pipeline,Run a vulnerability security scanner as part of your continuous-integration /continuous-delivery (CI/CD) pipeline,
"For this question, refer to the EHR Healthcare case study. You need to define the technical architecture for securely deploying workloads to Google Cloud. You also need to ensure that only verified containers are deployed using Google Cloud services. What should you do? (Choose two.)
",Configure Jenkins to utilize Kritis to cryptographically sign a container as part of a CI/CD pipeline.,Configure Container Registry to use vulnerability scanning to confirm that there are no vulnerabilities before deploying the workload.,,,"Enable Binary Authorization on GKE, and sign containers as part of a CI/CD pipeline.",Configure Container Registry to only allow trusted service accounts to create and deploy containers from the registry.,
"You are using Cloud CDN to deliver static HTTP(S) website content hosted on a Compute Engine instance group. You want to improve the cache hit ratio.
What should you do?
",Shorten the expiration time of the cached objects.,Make sure the HTTP(S) header ג€Cache-Regionג€ points to the closest region of your users.,Replicate the static content in a Cloud Storage bucket. Point CloudCDN toward a load balancer on that bucket.,,Customize the cache keys to omit the protocol from the key.,,
"Your company has a Google Cloud project that uses BigQuery for data warehousing. There are some tables that contain personally identifiable information (PII).
Only the compliance team may access the PII. The other information in the tables must be available to the data science team. You want to minimize cost and the time it takes to assign appropriate access to the tables. What should you do?
","1. From the dataset where you have the source data, create views of tables that you want to share, excluding PII. 2. Assign an appropriate project-level IAM role to the members of the data science team. 3. Assign access controls to the dataset that contains the view.","1. From the dataset where you have the source data, create materialized views of tables that you want to share, excluding PII. 2. Assign an appropriate project-level IAM role to the members of the data science team. 3. Assign access controls to the dataset that contains the view.","1. Create a dataset for the data science team. 2. Create materialized views of tables that you want to share, excluding PII. 3. Assign an appropriate project-level IAM role to the members of the data science team. 4. Assign access controls to the dataset that contains the view. 5. Authorize the view to access the source dataset.",,"1. Create a dataset for the data science team. 2. Create views of tables that you want to share, excluding PII. 3. Assign an appropriate project-level IAM role to the members of the data science team. 4. Assign access controls to the dataset that contains the view. 5. Authorize the view to access the source dataset.",,
"Your company provides a recommendation engine for retail customers. You are providing retail customers with an API where they can submit a user ID and the API returns a list of recommendations for that user. You are responsible for the API lifecycle and want to ensure stability for your customers in case the API makes backward-incompatible changes. You want to follow Google-recommended practices. What should you do?
",Create a distribution list of all customers to inform them of an upcoming backward-incompatible change at least one month before replacing the old API with the new API.,"Create an automated process to generate API documentation, and update the public API documentation as part of the CI/CD process when deploying an update to the API.",Use a versioning strategy for the APIs that adds the suffix ג€DEPRECATEDג€ to the current API version number on every backward-incompatible change. Use the current version number for the new API.,,Use a versioning strategy for the APIs that increases the version number on every backward-incompatible change.,,
"Your company has a Kubernetes application that pulls messages from Pub/Sub and stores them in Filestore. Because the application is simple, it was deployed as a single pod. The infrastructure team has analyzed Pub/Sub metrics and discovered that the application cannot process the messages in real time. Most of them wait for minutes before being processed. You need to scale the elaboration process that is I/O-intensive. What should you do?
",Use kubectl autoscale deployment APP_NAME --max 6 --min 2 --cpu-percent 50 to configure Kubernetes autoscaling deployment.,Configure a Kubernetes autoscaling deployment based on the subscription/push_request_latencies metric.,Use the --enable-autoscaling flag when you create the Kubernetes cluster.,,Configure a Kubernetes autoscaling deployment based on the subscription/num_undelivered_messages metric.,,
"You are working at a sports association whose members range in age from 8 to 30. The association collects a large amount of health data, such as sustained injuries. You are storing this data in BigQuery. Current legislation requires you to delete such information upon request of the subject. You want to design a solution that can accommodate such a request. What should you do?
","When ingesting new data in BigQuery, run the data through the Data Loss Prevention (DLP) API to identify any personal information. As part of the DLP scan, save the result to Data Catalog. Upon a deletion request, query Data Catalog to find the column with personal information.","Create a BigQuery view over the table that contains all data. Upon a deletion request, exclude the rows that affect the subject's data from this view. Use this view instead of the source table for all analysis tasks.","Use a unique identifier for each individual. Upon a deletion request, overwrite the column with the unique identifier with a salted SHA256 of its value.",,"Use a unique identifier for each individual. Upon a deletion request, delete all rows from BigQuery with this identifier.",,
"What are two of the actions you can take to troubleshoot a virtual machine instance that won't start up at all? (Select 2 answers.)
",Increase the CPU and memory on the instance by changing the machine type.,Connect to your virtual machine instance using SSH.,,,Validate that your disk has a valid file system.,Examine your virtual machine instance's serial port output.,
"Mountkirk Games wants you to design their new testing strategy. How should the test coverage differ from their existing backends on the other platforms?
","Unit tests are no longer required, only end-to-end tests",Tests should be applied after the release is in the production environment,Tests should include directly testing the Google Cloud Platform (GCP) infrastructure,,Tests should scale well beyond the prior approaches,,
"You have an application deployed on Google Kubernetes Engine using a Deployment named echo-deployment. The deployment is exposed using a Service called echo-service. You need to perform an update to the application with minimal downtime to the application. What should you do?
",Use the rolling update functionality of the Instance Group behind the Kubernetes cluster,"Update the deployment yaml file with the new container image. Use kubectl delete deployment/echo-deployment and kubectl create ג€""f <yaml-file>","Update the service yaml file which the new container image. Use kubectl delete service/echo-service and kubectl create ג€""f <yaml-file>",,Use kubectl set image deployment/echo-deployment <new-image>,,
"You need to ensure reliability for your application and operations by supporting reliable task scheduling for compute on GCP. Leveraging Google best practices, what should you do?
","Using the Cron service provided by App Engine, publish messages directly to a message-processing utility service running on Compute Engine instances.","Using the Cron service provided by Google Kubernetes Engine (GKE), publish messages directly to a message-processing utility service running on Compute Engine instances.","Using the Cron service provided by GKE, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message-processing utility service running on Compute Engine instances.",,"Using the Cron service provided by App Engine, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message-processing utility service running on Compute Engine instances.",,
"For this question, refer to the TerramEarth case study. You are building a microservice-based application for TerramEarth. The application is based on Docker containers. You want to follow Google-recommended practices to build the application continuously and store the build artifacts. What should you do?
","Configure a trigger in Cloud Build for new source changes. The trigger invokes build jobs and build container images for the microservices. Tag the images with a version number, and push them to Cloud Storage.","Create a Scheduler job to check the repo every minute. For any new change, invoke Cloud Build to build container images for the microservices. Tag the images using the current timestamp, and push them to the Container Registry.","Configure a trigger in Cloud Build for new source changes. Invoke Cloud Build to build one container image, and tag the image with the label 'latest.' Push the image to the Container Registry.",,"Configure a trigger in Cloud Build for new source changes. Invoke Cloud Build to build container images for each microservice, and tag them using the code commit hash. Push the images to the Container Registry.",,
"Your company is developing a web-based application. You need to make sure that production deployments are linked to source code commits and are fully auditable. What should you do?
",Make sure a developer is tagging the code commit with the date and time of commit.,Make sure a developer is adding a comment to the commit that links to the deployment.,Make sure the developer is tagging the commits with latest.,,Make the container tag match the source code commit hash.,,
"An application development team has come to you for advice. They are planning to write and deploy an HTTP(S) API using Go 1.12. The API will have a very unpredictable workload and must remain reliable during peaks in traffic. They want to minimize operational overhead for this application. Which approach should you recommend?
","Develop the application with containers, and deploy to Google Kubernetes Engine.",Use a Managed Instance Group when deploying to Compute Engine.,"Develop the application for App Engine flexible environment, using a custom runtime.",,Develop the application for App Engine standard environment.,,
"Your company has an application running on App Engine that allows users to upload music files and share them with other people. You want to allow users to upload files directly into Cloud Storage from their browser session. The payload should not be passed through the backend. What should you do?
","1. Set a CORS configuration in the target Cloud Storage bucket where the base URL of the App Engine application is an allowed origin.
2. Assign the Cloud Storage WRITER role to users who upload files.","1. Use the Cloud Storage Signed URL feature to generate a POST URL.
2. Use App Engine default credentials to sign requests against Cloud Storage.","1. Assign the Cloud Storage WRITER role to users who upload files.
2. Use App Engine default credentials to sign requests against Cloud Storage.",,"1. Set a CORS configuration in the target Cloud Storage bucket where the base URL of the App Engine application is an allowed origin.
2. Use the Cloud Storage Signed URL feature to generate a POST URL.",,
"You are developing your microservices application on Google Kubernetes Engine. During testing, you want to validate the behavior of your application in case a specific microservice should suddenly crash. What should you do?
","Add a taint to one of the nodes of the Kubernetes cluster. For the specific microservice, configure a pod anti-affinity label that has the name of the tainted node as a value.",Destroy one of the nodes of the Kubernetes cluster to observe the behavior.,Configure Istio's traffic management features to steer the traffic away from a crashing microservice.,,Use Istio's fault injection on the particular microservice whose faulty behavior you want to simulate.,,
"Your company recently acquired a company that has infrastructure in Google Cloud. Each company has its own Google Cloud organization. Each company is using a Shared Virtual Private Cloud (VPC) to provide network connectivity for its applications. Some of the subnets used by both companies overlap. In order for both businesses to integrate, the applications need to have private network connectivity. These applications are not on overlapping subnets. You want to provide connectivity with minimal re-engineering. What should you do?
",Set up VPC peering and peer each Shared VPC together.,Migrate the projects from the acquired company into your company's Google Cloud organization. Re-launch the instances in your companies Shared VPC.,Configure SSH port forwarding on each application to provide connectivity between applications in the different Shared VPCs.,,Set up a Cloud VPN gateway in each Shared VPC and peer Cloud VPNs.,,
"Your company has a Google Cloud project that uses BigQuery for data warehousing. They have a VPN tunnel between the on-premises environment and Google Cloud that is configured with Cloud VPN. The security team wants to avoid data exfiltration by malicious insiders, compromised code, and accidental oversharing.
What should they do?
",Configure Private Google Access for on-premises only.,Perform the following tasks: 1. Create a service account. 2. Give the BigQuery JobUser role and Storage Reader role to the service account. 3. Remove all other IAM access from the project.,Configure Private Google Access.,,Configure VPC Service Controls and configure Private Google Access.,,
"Your company is planning to migrate their Windows Server 2022 from their on-premises data center to Google Cloud. You need to bring the licenses that are currently in use in on-premises virtual machines into the target cloud environment. What should you do?
","1. Create an image of the on-premises virtual machines and upload into Cloud Storage.
2. Import the image as a virtual disk on Compute Engine.","1. Create standard instances on Compute Engine.
2. Select as the OS the same Microsoft Windows version that is currently in use in the on-premises environment.","1. Create an image of the on-premises virtual machine.
2. Import the image as a virtual disk on Compute Engine.
3. Create a standard instance on Compute Engine, selecting as the OS the same Microsoft Windows version that is currently in use in the on-premises environment.
4. Attach a data disk that includes data that matches the created image.",,"1. Create an image of the on-premises virtual machines.
2. Import the image as a virtual disk on Compute Engine using --os=windows-2022-dc-v.
3. Create a sole-tenancy instance on Compute Engine that uses the imported disk as a boot disk.",,
"Mountkirk Games wants to set up a continuous delivery pipeline. Their architecture includes many small services that they want to be able to update and roll back quickly. Mountkirk Games has the following requirements:
✑ Services are deployed redundantly across multiple regions in the US and Europe
✑ Only frontend services are exposed on the public internet
✑ They can provide a single frontend IP for their fleet of services
✑ Deployment artifacts are immutable
Which set of products should they use?
","Google Cloud Storage, Google Cloud Dataflow, Google Compute Engine","Google Cloud Storage, Google App Engine, Google Network Load Balancer","Google Cloud Functions, Google Cloud Pub/Sub, Google Cloud Deployment Manager",,"Google Kubernetes Registry, Google Container Engine, Google HTTP(S) Load Balancer",,
"For this question, refer to the TerramEarth case study. You have broken down a legacy monolithic application into a few containerized RESTful microservices.
You want to run those microservices on Cloud Run. You also want to make sure the services are highly available with low latency to your customers. What should you do?
",Deploy Cloud Run services to multiple availability zones. Create Cloud Endpoints that point to the services. Create a global HTTP(S) Load Balancing instance and attach the Cloud Endpoints to its backend.,"Deploy Cloud Run services to multiple regions. In Cloud DNS, create a latency-based DNS name that points to the services.",Deploy Cloud Run services to multiple availability zones. Create a TCP/IP global load balancer. Add the Cloud Run Endpoints to its backend service.,,Deploy Cloud Run services to multiple regions. Create serverless network endpoint groups pointing to the services. Add the serverless NEGs to a backend service that is used by a global HTTP(S) Load Balancing instance.,,
"Your company's test suite is a custom C++ application that runs tests throughout each day on Linux virtual machines. The full test suite takes several hours to complete, running on a limited number of on-premises servers reserved for testing. Your company wants to move the testing infrastructure to the cloud, to reduce the amount of time it takes to fully test a change to the system, while changing the tests as little as possible.
Which cloud infrastructure should you recommend?
",Google Compute Engine unmanaged instance groups and Network Load Balancer,Google Cloud Dataproc to run Apache Hadoop jobs to process each test,Google App Engine with Google StackDriver for logging,,Google Compute Engine managed instance groups with auto-scaling,,